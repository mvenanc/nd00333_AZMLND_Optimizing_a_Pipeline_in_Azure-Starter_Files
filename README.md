# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a bank term deposit

The best performing model was a Logistic Regression

The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a bank term deposit


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline architecture is based in a flow of data acsition. After the acsition, there is a phase of data cleaning where data missing is removed and categorical features are encoded. The next step occurs a data split into training and evaluation slices. Then, a Logistic Regression with only two parameters which are : Inverse of regularization strenght and max number of iterations. To find the best parameters, there is a step which runs overs the pipeline mentioned that is Hyperparameter tunning. This step produces a series of possible values for parameters and than test the model for each parameter set of combination. 

**What are the benefits of the parameter sampler you chose?**
Search in a more diverse space the best parameters to achieve a better model performance Accuracy.


**What are the benefits of the early stopping policy you chose?**
Defines an early termination policy based on slack criteria, and a frequency and delay interval for evaluation.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
There were generated around of 43 models, and the best approach was an Ensemble approach made mostly by LightGBM, XGBoost and Random Forest. I could not access the parameters that have been used.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Using the hyperparameter tunning for a Logist Regression approach, the Accuracy was 0.91031, in the other hand, when using AutoML approach, the best Accuracy was 0.91806. 
The arquiteture of the two approaches were totally different. In the first, it as using just on kind of algorithm, which was Logist Regression. This limited our space of possibilities to find the best algorithm and the best set of hyperparameters. In the second approach, autom ml can parallelize several different runs and each run can handle different algorithm and different set of hyperparameters. This is made automatically and then, aour searh space for the best model and hyperparameters increase.  


## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
Yes, there are. For example, once the auto ml found that GBM approach seems better, it may be possible to use Hyperparameter tunning for Light GBM algorithm in attempt to find best hyperparameters for this model. It may result in yet best model. As well, the dataset is imbalanced. It is a good approach to avoid sintetic sampling algorithms. Another good approach is to try to balance the data before running any approach mentioned here for machine learning.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**

![](images/cluster_delete.png?raw=true)
